{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpXfJ6XXLtTe"
      },
      "outputs": [],
      "source": [
        "from math import floor\n",
        "import numpy as np\n",
        "\n",
        "def row_col_to_seq(row_col, num_cols):  #Converts state number to row_column format\n",
        "    return row_col[:,0] * num_cols + row_col[:,1]\n",
        "\n",
        "def seq_to_col_row(seq, num_cols): #Converts row_column format to state number\n",
        "    r = floor(seq / num_cols)\n",
        "    c = seq - r * num_cols\n",
        "    return np.array([[r, c]])\n",
        "\n",
        "class GridWorld:\n",
        "    \"\"\"\n",
        "    Creates a gridworld object to pass to an RL algorithm.\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_rows : int\n",
        "        The number of rows in the gridworld.\n",
        "    num_cols : int\n",
        "        The number of cols in the gridworld.\n",
        "    start_state : numpy array of shape (1, 2), np.array([[row, col]])\n",
        "        The start state of the gridworld (can only be one start state)\n",
        "    goal_states : numpy arrany of shape (n, 2)\n",
        "        The goal states for the gridworld where n is the number of goal\n",
        "        states.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_rows, num_cols, start_state, goal_states, wind = False):\n",
        "        self.num_rows = num_rows\n",
        "        self.num_cols = num_cols\n",
        "        self.start_state = start_state\n",
        "        self.goal_states = goal_states\n",
        "        self.obs_states = None\n",
        "        self.bad_states = None\n",
        "        self.num_bad_states = 0\n",
        "        self.p_good_trans = None\n",
        "        self.bias = None\n",
        "        self.r_step = None\n",
        "        self.r_goal = None\n",
        "        self.r_dead = None\n",
        "        self.gamma = 1 # default is no discounting\n",
        "        self.wind = wind\n",
        "\n",
        "    def add_obstructions(self, obstructed_states=None, bad_states=None, restart_states=None):\n",
        "\n",
        "        self.obs_states = obstructed_states\n",
        "        self.bad_states = bad_states\n",
        "        if bad_states is not None:\n",
        "            self.num_bad_states = bad_states.shape[0]\n",
        "        else:\n",
        "            self.num_bad_states = 0\n",
        "        self.restart_states = restart_states\n",
        "        if restart_states is not None:\n",
        "            self.num_restart_states = restart_states.shape[0]\n",
        "        else:\n",
        "            self.num_restart_states = 0\n",
        "\n",
        "    def add_transition_probability(self, p_good_transition, bias):\n",
        "\n",
        "        self.p_good_trans = p_good_transition\n",
        "        self.bias = bias\n",
        "\n",
        "    def add_rewards(self, step_reward, goal_reward, bad_state_reward=None, restart_state_reward = None):\n",
        "\n",
        "        self.r_step = step_reward\n",
        "        self.r_goal = goal_reward\n",
        "        self.r_bad = bad_state_reward\n",
        "        self.r_restart = restart_state_reward\n",
        "\n",
        "\n",
        "    def create_gridworld(self):\n",
        "\n",
        "        self.num_actions = 4\n",
        "        self.num_states = self.num_cols * self.num_rows# +1\n",
        "        self.start_state_seq = row_col_to_seq(self.start_state, self.num_cols)\n",
        "        self.goal_states_seq = row_col_to_seq(self.goal_states, self.num_cols)\n",
        "\n",
        "        # rewards structure\n",
        "        self.R = self.r_step * np.ones((self.num_states, 1))\n",
        "        #self.R[self.num_states-1] = 0\n",
        "        self.R[self.goal_states_seq] = self.r_goal\n",
        "\n",
        "        for i in range(self.num_bad_states):\n",
        "            if self.r_bad is None:\n",
        "                raise Exception(\"Bad state specified but no reward is given\")\n",
        "            bad_state = row_col_to_seq(self.bad_states[i,:].reshape(1,-1), self.num_cols)\n",
        "            #print(\"bad states\", bad_state)\n",
        "            self.R[bad_state, :] = self.r_bad\n",
        "        for i in range(self.num_restart_states):\n",
        "            if self.r_restart is None:\n",
        "                raise Exception(\"Restart state specified but no reward is given\")\n",
        "            restart_state = row_col_to_seq(self.restart_states[i,:].reshape(1,-1), self.num_cols)\n",
        "            #print(\"restart_state\", restart_state)\n",
        "            self.R[restart_state, :] = self.r_restart\n",
        "\n",
        "        # probability model\n",
        "        if self.p_good_trans == None:\n",
        "            raise Exception(\"Must assign probability and bias terms via the add_transition_probability method.\")\n",
        "\n",
        "        self.P = np.zeros((self.num_states,self.num_states,self.num_actions))\n",
        "        for action in range(self.num_actions):\n",
        "            for state in range(self.num_states):\n",
        "\n",
        "\n",
        "                # check if the state is the goal state or an obstructed state - transition to end\n",
        "                row_col = seq_to_col_row(state, self.num_cols)\n",
        "                if self.obs_states is not None:\n",
        "                    end_states = np.vstack((self.obs_states, self.goal_states))\n",
        "                else:\n",
        "                    end_states = self.goal_states\n",
        "\n",
        "                if any(np.sum(np.abs(end_states-row_col), 1) == 0):\n",
        "                    self.P[state, state, action] = 1\n",
        "\n",
        "                # else consider stochastic effects of action\n",
        "                else:\n",
        "                    for dir in range(-1,2,1):\n",
        "\n",
        "                        direction = self._get_direction(action, dir)\n",
        "                        next_state = self._get_state(state, direction)\n",
        "                        if dir == 0:\n",
        "                            prob = self.p_good_trans\n",
        "                        elif dir == -1:\n",
        "                            prob = (1 - self.p_good_trans)*(self.bias)\n",
        "                        elif dir == 1:\n",
        "                            prob = (1 - self.p_good_trans)*(1-self.bias)\n",
        "\n",
        "                        self.P[state, next_state, action] += prob\n",
        "\n",
        "                # make restart states transition back to the start state with\n",
        "                # probability 1\n",
        "                if self.restart_states is not None:\n",
        "                    if any(np.sum(np.abs(self.restart_states-row_col),1)==0):\n",
        "                        next_state = row_col_to_seq(self.start_state, self.num_cols)\n",
        "                        self.P[state,:,:] = 0\n",
        "                        self.P[state,next_state,:] = 1\n",
        "        return self\n",
        "\n",
        "    def _get_direction(self, action, direction):\n",
        "\n",
        "        left = [2,3,1,0]\n",
        "        right = [3,2,0,1]\n",
        "        if direction == 0:\n",
        "            new_direction = action\n",
        "        elif direction == -1:\n",
        "            new_direction = left[action]\n",
        "        elif direction == 1:\n",
        "            new_direction = right[action]\n",
        "        else:\n",
        "            raise Exception(\"getDir received an unspecified case\")\n",
        "        return new_direction\n",
        "\n",
        "    def _get_state(self, state, direction):\n",
        "\n",
        "        row_change = [-1,1,0,0]\n",
        "        col_change = [0,0,-1,1]\n",
        "        row_col = seq_to_col_row(state, self.num_cols)\n",
        "        row_col[0,0] += row_change[direction]\n",
        "        row_col[0,1] += col_change[direction]\n",
        "\n",
        "        # check for invalid states\n",
        "        if self.obs_states is not None:\n",
        "            if (np.any(row_col < 0) or\n",
        "                np.any(row_col[:,0] > self.num_rows-1) or\n",
        "                np.any(row_col[:,1] > self.num_cols-1) or\n",
        "                np.any(np.sum(abs(self.obs_states - row_col), 1)==0)):\n",
        "                next_state = state\n",
        "            else:\n",
        "                next_state = row_col_to_seq(row_col, self.num_cols)[0]\n",
        "        else:\n",
        "            if (np.any(row_col < 0) or\n",
        "                np.any(row_col[:,0] > self.num_rows-1) or\n",
        "                np.any(row_col[:,1] > self.num_cols-1)):\n",
        "                next_state = state\n",
        "            else:\n",
        "                next_state = row_col_to_seq(row_col, self.num_cols)[0]\n",
        "\n",
        "        return next_state\n",
        "\n",
        "    def reset(self):\n",
        "      return int(self.start_state_seq)\n",
        "\n",
        "    def step(self, state, action):\n",
        "        p, r = 0, np.random.random()\n",
        "        for next_state in range(self.num_states):\n",
        "\n",
        "            p += self.P[state, next_state, action]\n",
        "\n",
        "            if r <= p:\n",
        "                break\n",
        "\n",
        "        if(self.wind and np.random.random() < 0.4):\n",
        "\n",
        "          arr = self.P[next_state, :, 3]\n",
        "          next_next = np.where(arr == np.amax(arr))\n",
        "          next_next = next_next[0][0]\n",
        "          return next_next, self.R[next_next]\n",
        "        else:\n",
        "          return next_state, self.R[next_state]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqE09JUiL1B8"
      },
      "outputs": [],
      "source": [
        "# specify world parameters\n",
        "num_cols = 10\n",
        "num_rows = 10\n",
        "obstructions = np.array([[0,7],[1,1],[1,2],[1,3],[1,7],[2,1],[2,3],\n",
        "                         [2,7],[3,1],[3,3],[3,5],[4,3],[4,5],[4,7],\n",
        "                         [5,3],[5,7],[5,9],[6,3],[6,9],[7,1],[7,6],\n",
        "                         [7,7],[7,8],[7,9],[8,1],[8,5],[8,6],[9,1]])\n",
        "bad_states = np.array([[1,9],[4,2],[4,4],[7,5],[9,9]])\n",
        "restart_states = np.array([[3,7],[8,2]])\n",
        "start_state = np.array([[3,6]])\n",
        "goal_states = np.array([[0,9],[2,2],[8,7]])\n",
        "\n",
        "# create model\n",
        "gw = GridWorld(num_rows=num_rows,\n",
        "               num_cols=num_cols,\n",
        "               start_state=start_state,\n",
        "               goal_states=goal_states, wind = False)\n",
        "gw.add_obstructions(obstructed_states=obstructions,\n",
        "                    bad_states=bad_states,\n",
        "                    restart_states=restart_states)\n",
        "gw.add_rewards(step_reward=-1,\n",
        "               goal_reward=10,\n",
        "               bad_state_reward=-6,\n",
        "               restart_state_reward=-100)\n",
        "gw.add_transition_probability(p_good_transition=0.7,\n",
        "                              bias=0.5)\n",
        "env = gw.create_gridworld()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UdRce8oMZNb",
        "outputId": "ee3858e1-e109-42e6-80eb-336702f708e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of actions 4\n",
            "Number of states 100\n",
            "start state [36]\n",
            "goal state(s) [ 9 22 87]\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of actions\", env.num_actions) #0 -> UP, 1-> DOWN, 2 -> LEFT, 3-> RIGHT\n",
        "print(\"Number of states\", env.num_states)\n",
        "print(\"start state\", env.start_state_seq)\n",
        "print(\"goal state(s)\", env.goal_states_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hacJEN8R_Bb",
        "outputId": "73a43c59-ffdf-44f0-f6d0-c66cda564946"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.85, 0.15, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
              "       0.  ])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.P[0,:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elgVvvFROUTZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}